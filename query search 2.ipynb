{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "#NOTlinks = pd.read_csv('webpages/NOTlinks.csv', names=['Code', 'Title'], header = 0)\n",
    "#dfList = list(NOTlinks['Code']) + [9429, 9671]\n",
    "voc = json.load(open('vocabulary.json'))\n",
    "inverted_index = json.load(open('inverted_index.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26137"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc['sun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF (Term Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate data frequency\n",
    "\n",
    "dict_freq = {}\n",
    "for i in range(10000):\n",
    "    file = open('webpages/tsv clean/filtered_%d.tsv'%i).read().split('\\n\\n')[1]\n",
    "    tabs = file.split('\\t')[1]+file.split('\\t')[2]  # list of words in intro and plots\n",
    "    for word in tabs.split():            \n",
    "        if word not in dict_freq.keys():\n",
    "            dict_freq[word] = {i: [tabs.split().count(word)/len(tabs.split())]}\n",
    "        else:\n",
    "            dict_freq[word][i] = [tabs.split().count(word)/len(tabs.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the data frequency of a word in a document\n",
    "\n",
    "def df(term, document_id):  # term is a string, document_id an integer\n",
    "    dict_freq[term][document_id][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compact function (without storing the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_freq(term, i):   # (string, integer)\n",
    "    file = open('webpages/tsv clean/filtered_%d.tsv'%i).read().split('\\n\\n')[1]\n",
    "    tabs = file.split('\\t')[1]+file.split('\\t')[2]  # list of words in intro and plots\n",
    "    if term in tabs.split():\n",
    "        df = tabs.split().count(term)/len(tabs.split())\n",
    "    else:\n",
    "        df = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021739130434782608"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_freq('sun', 9929)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF (Inverse Data Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inverse Data Frequency\n",
    "\n",
    "idf = {}\n",
    "N = 9898\n",
    "for word in voc:\n",
    "    val = len(inverted_index[str(voc[word])])\n",
    "    idf[word] = math.log(N/val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compact function (without storing the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "def idf(term):\n",
    "    val = len(inverted_index[str(voc[term])])  # this is the number of documents containing the given word\n",
    "    return math.log(N/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.521460917862246"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('sun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency - Inverse Data Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TF-IDF\n",
    "\n",
    "for word in dict_freq:\n",
    "    for document_id in dict_freq[word].keys():\n",
    "        dict_freq[word][document_id].append(dict_freq[word][document_id][0]*idf[word])\n",
    "\n",
    "# dict_freq is a dictionary with the words as keys and as values a list whose elements are {document_id : [df_{word}, TF-IDF_{document_id, word}]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(term_id, document_id): # (integer, integer)\n",
    "    return data_freq(get_key(term_id), document_id)*idf(get_key(term_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12003175908396187"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(26137, 9929)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted index with TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Inverted Index with TF-IDF score\n",
    "\n",
    "inverted_index_freq = dict.fromkeys(range(len(voc)))\n",
    "for term_id in inverted_index_freq.keys():\n",
    "    for document_id in inverted_index[str(term_id)]:\n",
    "        if inverted_index_freq[term_id] == None:\n",
    "            inverted_index_freq[term_id] = [(document_id, tfidf(term_id, document_id))]\n",
    "        else:\n",
    "            inverted_index_freq[term_id] += [(document_id, tfidf(term_id, document_id))]\n",
    "            \n",
    "# The new inverted_index_freq is as follow: {term_id : [document_id, TF-IDF_{document_id, term}]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index_freq.json', 'w') as fp:\n",
    "    json.dump(inverted_index_freq, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function returns the TF-IDF of the given word in the given document\n",
    "\n",
    "def tfidf2(term_id, document_id):  # term_id is a string here, document_id an integer\n",
    "    for doc in inverted_index_freq[term_id]:\n",
    "        if doc[0][0] == document_id:\n",
    "            return doc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the a term given its term_id\n",
    "\n",
    "def get_key(term_id): \n",
    "    for key, value in voc.items(): \n",
    "         if term_id == value:\n",
    "                return key   \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search engine 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "ps = PorterStemmer()\n",
    "urls = json.load(open('urls.json'))\n",
    "inverted_index = json.load(open('inverted_index.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query vector\n",
    "\n",
    "def query_vector(query):\n",
    "    query_vector = {}\n",
    "    for word in query:  # words are strings\n",
    "        df = query.count(word)/len(query)\n",
    "        query_vector[voc[word]] = df * idf(word)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the vector of a certain document\n",
    "\n",
    "def vector(i):  # integer\n",
    "    vec = {}\n",
    "    file = open('webpages/tsv clean/filtered_%d.tsv'%i).read().split('\\n\\n')[1]\n",
    "    tabs = file.split('\\t')[1]+file.split('\\t')[2]  # list of words in intro and plots\n",
    "    for word in tabs.split():\n",
    "        vec[voc[word]] = tfidf(voc[word], i)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query_vec, document_id):  # (dict, integer)\n",
    "    norm_query = math.sqrt(sum(n**2 for n in query_vec.values()))\n",
    "    norm_doc = math.sqrt(sum(tfidf(word,document_id) for word in vector(document_id)))\n",
    "    dot_pr = 0\n",
    "    for word in query_vec.keys():\n",
    "        dot_pr += query_vec[word]*tfidf(word, document_id)  # (string, integer)\n",
    "    return dot_pr/(norm_query*norm_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of the query search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english united states love\n"
     ]
    }
   ],
   "source": [
    "query = input().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input:\n",
    "\n",
    "for i in range(len(query)):\n",
    "    if not query[i] in stop_words and query[i].isalnum():\n",
    "        query[i] = ps.stem(query[i])\n",
    "    else:\n",
    "        del query[i]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the term_id of the words in the query (integers)\n",
    "query_index = [voc[word] for word in query]\n",
    "\n",
    "# Get the document_if of the documents containing the words in the query\n",
    "allDOC = [inverted_index[str(word)] for word in query_index]\n",
    "query_match = set(allDOC[0]).intersection(*allDOC[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the query vector\n",
    "\n",
    "query_vec = query_vector(query)\n",
    "\n",
    "# Rank the results by cosine similarity\n",
    "\n",
    "# Show the result of the query in a dataframe\n",
    "\n",
    "df = pd.DataFrame(columns=['Title','Intro','Wikipedia Url', 'Similarity'])\n",
    "\n",
    "def make_clickable(val):  # function that make the links clickable\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "for i in query_match:\n",
    "    file = open('webpages/tsv/output_%d.tsv' %i).read().split('\\n\\n')[1].split('\\t')\n",
    "    title, intro, link = file[3].encode('utf8').decode(\"unicode_escape\"), file[1].encode('utf8').decode(\"unicode_escape\"), urls[str(i)]\n",
    "    sim = cosine_similarity(query_vec, i)\n",
    "    new_row = {'Title':title, 'Intro': intro, 'Wikipedia Url': link, 'Similarity': sim}\n",
    "    df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_66fda9c6_064d_11ea_994a_f12e0c80e534 th {\n",
       "          text-align: center;\n",
       "    }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col0 {\n",
       "            text-align:  center;\n",
       "            width:  130px;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col1 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col2 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col3 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col0 {\n",
       "            text-align:  center;\n",
       "            width:  130px;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col1 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col2 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col3 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col0 {\n",
       "            text-align:  center;\n",
       "            width:  130px;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col1 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col2 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col3 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col0 {\n",
       "            text-align:  center;\n",
       "            width:  130px;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col1 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col2 {\n",
       "            text-align:  center;\n",
       "        }    #T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col3 {\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Title</th>        <th class=\"col_heading level0 col1\" >Intro</th>        <th class=\"col_heading level0 col2\" >Wikipedia Url</th>        <th class=\"col_heading level0 col3\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col0\" class=\"data row0 col0\" >A Farewell to Arms</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col1\" class=\"data row0 col1\" >A Farewell to Arms is a 1932 American pre-Code romance drama film directed by Frank Borzage and starring Helen Hayes, Gary Cooper, and Adolphe Menjou.[2] Based on the 1929 semi-autobiographical novel A Farewell to Arms by Ernest Hemingway, with a screenplay by Oliver H.P. Garrett and Benjamin Glazer, the film is about a tragic romantic love affair between an American ambulance driver and an English nurse in Italy during World War I. The film received Academy Awards for Best Cinematography and Best Sound, and was nominated for Best Picture and Best Art Direction.[2]\n",
       "</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col2\" class=\"data row0 col2\" ><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/A_Farewell_to_Arms_(1932_film)\">https://en.wikipedia.org/wiki/A_Farewell_to_Arms_(1932_film)</a></td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row0_col3\" class=\"data row0 col3\" >0.0592752</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col0\" class=\"data row1 col0\" >The Gilded Lily</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col1\" class=\"data row1 col1\" >The Gilded Lily is a 1935 American romantic comedy film directed by Wesley Ruggles and starring Claudette Colbert, Fred MacMurray, Ray Milland, and C. Aubrey Smith. The production's screenplay, written by Claude Binyon, is about a stenographer who becomes a famous cafÃ© entertainer courted by an English aristocrat and an American newspaper reporter. Released by Paramount Pictures in the United States on January 25, 1935, the film is one of the English language films chosen by the National Board of Review for its top-10 list of 1935. The Gilded Lily is also the first of seven films in which Claudette Colbert and Fred MacMurray costar.\n",
       "</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col2\" class=\"data row1 col2\" ><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/The_Gilded_Lily_(1935_film)\">https://en.wikipedia.org/wiki/The_Gilded_Lily_(1935_film)</a></td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row1_col3\" class=\"data row1 col3\" >0.0531571</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col0\" class=\"data row2 col0\" >Ace Eli and Rodger of the Skies</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col1\" class=\"data row2 col1\" >Ace Eli and Rodger of the Skies is a 1973 American adventure-comedy film based on a story by Steven Spielberg. The film centers on a barnstorming pilot (Cliff Robertson) and his son (Eric Shea) as they fly around the United States in the 1920s, having adventures along the way. English actress Pamela Franklin provided the love interest. One of the driving forces behind the production, Robertson was a pilot in real life, although Hollywood stunt pilot Frank Tallman flew most of the aerial scenes.[3]\n",
       "</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col2\" class=\"data row2 col2\" ><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Ace_Eli_and_Rodger_of_the_Skies\">https://en.wikipedia.org/wiki/Ace_Eli_and_Rodger_of_the_Skies</a></td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row2_col3\" class=\"data row2 col3\" >0.0338266</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col0\" class=\"data row3 col0\" >Munster, Go Home!</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col1\" class=\"data row3 col1\" >Munster, Go Home! is a 1966 American comedy horror film based on the hit 1960s family television sitcom The Munsters. It was directed by Earl Bellamy, who also directed a number of episodes in the series. The film was produced immediately after the television series completed filming for its original run, and included the original cast with the exception of Marilyn, who was played by Debbie Watson replacing Pat Priest from the series.\n",
       "</td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col2\" class=\"data row3 col2\" ><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Munster,_Go_Home!\">https://en.wikipedia.org/wiki/Munster,_Go_Home!</a></td>\n",
       "                        <td id=\"T_66fda9c6_064d_11ea_994a_f12e0c80e534row3_col3\" class=\"data row3 col3\" >0.0318399</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24a6d3c0f28>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of the top 5 documents related to the query\n",
    "\n",
    "d = dict(selector=\"th\", props=[('text-align', 'center')])\n",
    "df1 = df.sort_values(by=['Similarity'], ascending = False).head(5)\n",
    "df1.style.format({'Wikipedia Url': make_clickable}).hide_index().set_table_styles([d]).set_properties(**{'text-align': 'center'}).set_properties(subset=['Title'], **{'width': '130px'})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
